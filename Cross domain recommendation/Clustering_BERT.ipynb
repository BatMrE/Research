{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p4_KevKuu1C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT + Clustering"
      ],
      "metadata": {
        "id": "x81MK81FtcoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "\n",
        "# Load the dataframes\n",
        "df_movie = pd.read_csv('/content/movie_df_comm.csv')\n",
        "df_book = pd.read_csv('/content/book_df_comm.csv')\n",
        "\n",
        "# Concatenate dataframes\n",
        "df = pd.concat([df_book, df_movie], ignore_index=True)\n",
        "\n",
        "# Drop duplicates and missing values\n",
        "df = df.drop_duplicates(subset=['reviewerID', 'asin'])\n",
        "df = df.dropna(subset=['reviewerID', 'asin', 'overall'])\n",
        "\n",
        "# Generate unique user and item IDs\n",
        "df['user_id'] = df['reviewerID'].astype('category').cat.codes\n",
        "df['item_id'] = df['asin'].astype('category').cat.codes\n",
        "\n",
        "# Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the dataframes for later use\n",
        "train_df.to_pickle(\"train_df.pkl\")\n",
        "test_df.to_pickle(\"test_df.pkl\")\n",
        "\n",
        "# Initialize BERT model and tokenizer\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "# Function to generate BERT embeddings\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy().flatten()\n",
        "\n",
        "# Apply BERT embedding to item descriptions\n",
        "train_df['item_embedding'] = train_df['description'].apply(get_bert_embedding)\n",
        "train_df.to_pickle(\"train_df_with_embeddings.pkl\")\n",
        "\n",
        "# Generate user embeddings by averaging the embeddings of items they interacted with\n",
        "user_embeddings = train_df.groupby('user_id')['item_embedding'].apply(lambda x: np.mean(np.vstack(x), axis=0)).reset_index()\n",
        "user_embeddings = user_embeddings.rename(columns={'item_embedding': 'user_embedding'})\n",
        "\n",
        "# Merge user embeddings back to the train_df\n",
        "train_df = train_df.merge(user_embeddings, on='user_id')"
      ],
      "metadata": {
        "id": "G9WCO14atoN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Cluster users\n",
        "num_user_clusters = 10  # You can tune this parameter\n",
        "user_kmeans = KMeans(n_clusters=num_user_clusters, random_state=42)\n",
        "user_clusters = user_kmeans.fit_predict(np.vstack(user_embeddings['user_embedding']))\n",
        "user_embeddings['user_cluster'] = user_clusters\n",
        "\n",
        "# Cluster items\n",
        "num_item_clusters = 20  # You can tune this parameter\n",
        "item_embeddings = np.vstack(train_df['item_embedding'].values)\n",
        "item_kmeans = KMeans(n_clusters=num_item_clusters, random_state=42)\n",
        "item_clusters = item_kmeans.fit_predict(item_embeddings)\n",
        "train_df['item_cluster'] = item_clusters"
      ],
      "metadata": {
        "id": "xWSfSNawuPW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_items(user_id, user_embeddings, train_df, top_n=10):\n",
        "    # Check if the user exists in user_embeddings\n",
        "    user_data = user_embeddings[user_embeddings['user_id'] == user_id]\n",
        "\n",
        "    if user_data.empty:\n",
        "        # If the user is not in the training set, recommend popular items\n",
        "        popular_items = train_df['item_id'].value_counts().index[:top_n].tolist()\n",
        "        return popular_items[:top_n]\n",
        "\n",
        "    # Get the user's cluster\n",
        "    user_cluster = user_data['user_cluster'].values[0]\n",
        "\n",
        "    # Get items in the same cluster\n",
        "    cluster_items = train_df[train_df['item_cluster'] == user_cluster]['item_id'].unique()\n",
        "\n",
        "    # Get the items that the user has not interacted with\n",
        "    user_interacted_items = train_df[train_df['user_id'] == user_id]['item_id'].unique()\n",
        "    recommended_items = np.setdiff1d(cluster_items, user_interacted_items)\n",
        "\n",
        "    # If there are not enough items in the cluster, recommend popular items\n",
        "    if len(recommended_items) < top_n:\n",
        "        popular_items = train_df['item_id'].value_counts().index[:top_n].tolist()\n",
        "        recommended_items = np.concatenate([recommended_items, popular_items])\n",
        "\n",
        "    return recommended_items[:top_n]"
      ],
      "metadata": {
        "id": "KVwJCw0XuqWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recommendations(test_df, user_embeddings, train_df, top_n=10):\n",
        "    hit_rate = 0\n",
        "    ndcg = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    total_users = 0  # Count only users present in user_embeddings\n",
        "\n",
        "    for user_id in test_df['user_id'].unique():\n",
        "        # Check if the user exists in user_embeddings\n",
        "        if user_id not in user_embeddings['user_id'].values:\n",
        "            continue  # Skip users not in the training set\n",
        "\n",
        "        total_users += 1\n",
        "\n",
        "        # Get ground truth items for the user\n",
        "        ground_truth = test_df[test_df['user_id'] == user_id]['item_id'].values\n",
        "\n",
        "        # Generate recommendations for the user\n",
        "        recommended_items = recommend_items(user_id, user_embeddings, train_df, top_n)\n",
        "\n",
        "        # Calculate Hit Rate\n",
        "        if len(np.intersect1d(recommended_items, ground_truth)) > 0:\n",
        "            hit_rate += 1\n",
        "\n",
        "        # Calculate NDCG\n",
        "        relevance = np.isin(recommended_items, ground_truth).astype(int)\n",
        "        if np.sum(relevance) > 0:\n",
        "            ndcg += ndcg_score([relevance], [np.ones_like(relevance)], k=top_n)\n",
        "\n",
        "        # Calculate Precision and Recall\n",
        "        true_positives = len(np.intersect1d(recommended_items, ground_truth))\n",
        "        precision += true_positives / top_n\n",
        "        recall += true_positives / len(ground_truth)\n",
        "\n",
        "    # Avoid division by zero if no users are evaluated\n",
        "    if total_users == 0:\n",
        "        return 0, 0, 0, 0\n",
        "\n",
        "    # Average metrics across all evaluated users\n",
        "    hit_rate /= total_users\n",
        "    ndcg /= total_users\n",
        "    precision /= total_users\n",
        "    recall /= total_users\n",
        "\n",
        "    return hit_rate, ndcg, precision, recall"
      ],
      "metadata": {
        "id": "PLg_umzTusja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "hit_rate, ndcg, precision, recall = evaluate_recommendations(test_df, user_embeddings, train_df, top_n=10)\n",
        "print(f\"Hit Rate: {hit_rate:.4f}\")\n",
        "print(f\"NDCG: {ndcg:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r8Nw5MvvB2B",
        "outputId": "61cd1581-4fa5-48c6-870e-103e947515ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit Rate: 0.0009\n",
            "NDCG: 0.0004\n",
            "Precision: 0.0001\n",
            "Recall: 0.0009\n"
          ]
        }
      ]
    }
  ]
}